{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nS, nA = 750, 25\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask out actions that clinicians never taken\n",
    "Q_mask = np.load('action_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinician_policy = pickle.load(open('clinician_policy.p', 'rb'))\n",
    "pi_0 = np.zeros((nS, nA))\n",
    "for s, probs in clinician_policy.items():\n",
    "    for a, p in probs.items():\n",
    "        pi_0[s,a] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3056872 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.50236967, 0.02369668, 0.        , 0.03791469, 0.02132701,\n",
       "       0.09241706, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01658768, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 1e-10\n",
    "zeta = 0.05\n",
    "Q_pi = np.load('output_ql/svp_near-greedy_Q_gamma=0.99_zeta={}.npy'.format(zeta))\n",
    "Q_star = np.load('qlearn_Q.npy')\n",
    "V_star = np.nanmax(Q_star, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_SVP(Q_pi, Q_star):\n",
    "    # Construct the SVP\n",
    "    # Dictionary of {s: [a1, a2, ...]}\n",
    "    pi_svp = {}\n",
    "    for s in range(nS):\n",
    "        Q_cutoff = min(V_star[s], (1-zeta-tol) * V_star[s]) # lower bound for future return\n",
    "        Pi_s = np.argwhere(\n",
    "            np.where(Q_mask[s], Q_pi[s], -np.inf) > Q_cutoff\n",
    "        )\n",
    "        if len(Pi_s) > 0:\n",
    "            assert not np.isnan(Q_pi[s][Pi_s]).all()\n",
    "            pi_svp[s] = list(Pi_s.flatten())\n",
    "        else:\n",
    "            pi_svp[s] = [np.nanargmax(Q_star[s])] # fall back to the greedy action\n",
    "\n",
    "    # Tabular form, SxA, (s,a)=1 if a is included in Ï€(s)\n",
    "    PI_svp = np.zeros((nS, nA), dtype=int)\n",
    "    for s, pi_s in pi_svp.items():\n",
    "        for a in pi_s:\n",
    "            PI_svp[s,a] = 1\n",
    "    \n",
    "    return pi_svp, PI_svp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soften_policy(svp):\n",
    "    pi_e = np.zeros((nS, nA))\n",
    "    for s, probs in clinician_policy.items():\n",
    "        A_s = list(probs.keys())\n",
    "        a_star = list(np.argwhere(svp[s] == 1).flatten())\n",
    "        assert all(a_ in A_s for a_ in a_star)\n",
    "        if len(A_s) == len(a_star):\n",
    "            for a in A_s:\n",
    "                pi_e[s,a] = 1.0 / len(a_star)\n",
    "        else:\n",
    "            for a in A_s:\n",
    "                if a in a_star:\n",
    "                    pi_e[s,a] = 0.99 / len(a_star)\n",
    "                else:\n",
    "                    pi_e[s,a] = 0.01 / (len(A_s)-len(a_star))\n",
    "    return pi_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_svp, PI_svp = construct_SVP(Q_star, Q_star)\n",
    "pi_e = soften_policy(PI_svp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14285714, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14285714, 0.14285714, 0.        , 0.14285714, 0.14285714,\n",
       "       0.14285714, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14285714, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_e[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(pi_e.sum(axis=1), 1.0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_te = pickle.load(open('trajDr_te.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out unusable trajectories\n",
    "# must not contain (s,a) pairs not observed in the training set\n",
    "trajectories = []\n",
    "for traj in traj_te:\n",
    "    usable = True\n",
    "    for transition in traj:\n",
    "        s = transition['s']\n",
    "        a = transition['a']\n",
    "        if np.isclose(pi_0[s,a], 0.0):\n",
    "            usable = False\n",
    "            break\n",
    "    if usable:\n",
    "        trajectories.append(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective sample size of test set 2801\n"
     ]
    }
   ],
   "source": [
    "N = len(trajectories)\n",
    "print('Effective sample size of test set', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DR, WDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all per-step importance sampling ratio\n",
    "rho_all = []\n",
    "for traj in trajectories:\n",
    "    rho = []\n",
    "    for transition in traj:\n",
    "        s = transition['s']\n",
    "        a = transition['a']\n",
    "        rho_t = pi_e[s,a] / pi_0[s, a]\n",
    "        rho.append(rho_t)\n",
    "    rho_all.append(np.array(rho))\n",
    "\n",
    "# Find out the maximum trajectory length\n",
    "max_H = max(len(traj) for traj in trajectories)\n",
    "\n",
    "# Calculate cumulative importance ratio, rho_{1:t} for each trajectory at each timestep\n",
    "rho_cum = np.zeros((N, max_H))\n",
    "for i, rho in enumerate(rho_all):\n",
    "    rho_tmp = np.ones(max_H)\n",
    "    rho_tmp[:len(rho)] = rho\n",
    "    rho_cum[i] = np.cumprod(rho_tmp)\n",
    "\n",
    "# Calculate the average cumulative importance ratio at every horizon t\n",
    "weights = rho_cum.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubly_robust_estimator(trajectory, Q, pi_0, pi_e, rho_cumulative, gamma):\n",
    "    V_DR = 0\n",
    "    T = len(trajectory)\n",
    "    for t in range(T):\n",
    "        transition = trajectory[t]\n",
    "        s = transition['s']\n",
    "        a = transition['a']\n",
    "        r = transition['r']\n",
    "        \n",
    "        Q_hat = Q[s,a]\n",
    "        V_hat = np.nansum(Q[s] * pi_e[s])\n",
    "        assert not np.isclose(pi_0[s,a], 0.0)\n",
    "        rho_1t = rho_cumulative[t]\n",
    "        if t == 0:\n",
    "            rho_1t_1 = 1.0\n",
    "        else:\n",
    "            rho_1t_1 = rho_cumulative[t-1]\n",
    "        \n",
    "        V_DR = V_DR + np.power(gamma, t) * (rho_1t * r - (rho_1t * Q_hat - rho_1t_1 * V_hat))\n",
    "    \n",
    "    return V_DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_doubly_robust_estimator(trajectory, Q, pi_0, pi_e, rho_cumulative, weight_t, gamma):\n",
    "    V_WDR = 0\n",
    "    T = len(trajectory)\n",
    "    for t in range(T):\n",
    "        transition = trajectory[t]\n",
    "        s = transition['s']\n",
    "        a = transition['a']\n",
    "        r = transition['r']\n",
    "        \n",
    "        Q_hat = Q[s,a]\n",
    "        V_hat = np.nansum(Q[s] * pi_e[s])\n",
    "        assert not np.isclose(pi_0[s,a], 0.0)\n",
    "        rho_1t = rho_cumulative[t] / weight_t[t]\n",
    "        if t == 0:\n",
    "            rho_1t_1 = 1.0\n",
    "        else:\n",
    "            rho_1t_1 = rho_cumulative[t-1] / weight_t[t-1]\n",
    "        \n",
    "        V_WDR = V_WDR + np.power(gamma, t) * (rho_1t * r - (rho_1t * Q_hat - rho_1t_1 * V_hat))\n",
    "    \n",
    "    return V_WDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_DR = [\n",
    "    doubly_robust_estimator(traj, Q_star, pi_0, pi_e, rho_cumulative, gamma) \n",
    "    for traj, rho_cumulative in zip(trajectories, rho_cum)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.32283157244169"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.clip(V_DR, -100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 713.98it/s]\n"
     ]
    }
   ],
   "source": [
    "V_DR_b = []\n",
    "for i in tqdm(range(1000)):\n",
    "    V_DR_boot = utils.resample(V_DR, replace=True, random_state=i)\n",
    "    V_DR_b.append(np.mean(np.clip(V_DR_boot, -100, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84.32747698783487, 0.6343827995823593)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(V_DR_b), np.std(V_DR_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_WDR = [\n",
    "    weighted_doubly_robust_estimator(traj, Q_star, pi_0, pi_e, rho_cumulative, weights, gamma) \n",
    "    for traj, rho_cumulative in zip(trajectories, rho_cum)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.7260389134681"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.clip(V_WDR, -100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 790.44it/s]\n"
     ]
    }
   ],
   "source": [
    "V_WDR_b = []\n",
    "for i in tqdm(range(1000)):\n",
    "    V_WDR_boot = utils.resample(V_WDR, replace=True, random_state=i)\n",
    "    V_WDR_b.append(np.mean(np.clip(V_WDR_boot, -100, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89.73435102771438, 0.3184995008518237)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(V_WDR_b), np.std(V_WDR_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
