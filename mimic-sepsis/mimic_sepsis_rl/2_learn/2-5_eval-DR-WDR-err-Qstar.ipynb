{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nS, nA = 750, 25\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask out actions that clinicians never taken\n",
    "Q_mask = np.load('action_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinician_policy = pickle.load(open('clinician_policy.p', 'rb'))\n",
    "pi_0 = np.zeros((nS, nA))\n",
    "for s, probs in clinician_policy.items():\n",
    "    for a, p in probs.items():\n",
    "        pi_0[s,a] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3056872 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.50236967, 0.02369668, 0.        , 0.03791469, 0.02132701,\n",
       "       0.09241706, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01658768, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_star = np.load('qlearn_Q.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation policy\n",
    "# Soften policy\n",
    "pi_e = np.zeros((nS, nA))\n",
    "for s, probs in clinician_policy.items():\n",
    "    A_s = list(probs.keys())\n",
    "    a_star = np.nanargmax(Q_star[s])\n",
    "    assert a_star in probs.keys()\n",
    "    if len(probs) == 1:\n",
    "        for a, _ in probs.items():\n",
    "            pi_e[s,a] = 1.0\n",
    "    else:\n",
    "        for a, _ in probs.items():\n",
    "            if a == a_star:\n",
    "                pi_e[s,a] = 0.99\n",
    "            else:\n",
    "                pi_e[s,a] = 0.01 / (len(probs)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00166667, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00166667, 0.00166667, 0.        , 0.00166667, 0.99      ,\n",
       "       0.00166667, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00166667, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_e[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(pi_e.sum(axis=1), 1.0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_te = pickle.load(open('trajD_te.pkl', 'rb'))\n",
    "\n",
    "# Change rewards from {0, 1} to {-100, +100}\n",
    "for traj in traj_te:\n",
    "    traj[-1]['r'] = traj[-1]['r']*200-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out unusable trajectories\n",
    "# must not contain (s,a) pairs not observed in the training set\n",
    "trajectories = []\n",
    "for traj in traj_te:\n",
    "    usable = True\n",
    "    for transition in traj:\n",
    "        s = transition['s']\n",
    "        a = transition['a']\n",
    "        if np.isclose(pi_0[s,a], 0.0):\n",
    "            usable = False\n",
    "            break\n",
    "    if usable:\n",
    "        trajectories.append(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective sample size of test set 2801\n"
     ]
    }
   ],
   "source": [
    "N = len(trajectories)\n",
    "print('Effective sample size of test set', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior policy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed test set returns\n",
    "V_TEST = []\n",
    "for i, traj in enumerate(trajectories):\n",
    "    H = len(traj)\n",
    "    G = 0\n",
    "    for t in reversed(range(H)):\n",
    "        G = traj[t]['r'] + gamma * G\n",
    "    V_TEST.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.16317503128536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(V_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behavior_value(trajectories):\n",
    "    # Observed test set returns\n",
    "    V_TEST = []\n",
    "    for i, traj in enumerate(trajectories):\n",
    "        H = len(traj)\n",
    "        G = 0\n",
    "        for t in reversed(range(H)):\n",
    "            G = traj[t]['r'] + gamma * G\n",
    "        V_TEST.append(G)\n",
    "    return np.mean(V_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behavior_value_run_boot(trajectories, i):\n",
    "    traj_boot = utils.resample(trajectories, replace=True, random_state=i)\n",
    "    return get_behavior_value(traj_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:04<00:00,  8.00it/s]\n"
     ]
    }
   ],
   "source": [
    "V_TEST = []\n",
    "for i in tqdm(range(1000)):\n",
    "    V_TEST.append(get_behavior_value_run_boot(trajectories, i))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "V_TEST = Parallel(n_jobs=-1)(delayed(get_behavior_value_run_boot)(trajectories, i) for i in tqdm(range(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73.12608064951573, 0.9749614964346808)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(V_TEST), np.std(V_TEST)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "V_TEST = []\n",
    "for i in tqdm(range(1000)):\n",
    "    traj_boot = utils.resample(trajectories, replace=True, random_state=i)\n",
    "    val_ = get_behavior_value(traj_boot)\n",
    "    V_TEST.append(val_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DR, WDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all per-step importance sampling ratio\n",
    "rho_all = []\n",
    "for traj in trajectories:\n",
    "    rho = []\n",
    "    for transition in traj:\n",
    "        s = transition['s']\n",
    "        a = transition['a']\n",
    "        rho_t = pi_e[s,a] / pi_0[s, a]\n",
    "        rho.append(rho_t)\n",
    "    rho_all.append(np.array(rho))\n",
    "\n",
    "# Find out the maximum trajectory length\n",
    "max_H = max(len(traj) for traj in trajectories)\n",
    "\n",
    "# Calculate cumulative importance ratio, rho_{1:t} for each trajectory at each timestep\n",
    "rho_cum = np.zeros((N, max_H))\n",
    "for i, rho in enumerate(rho_all):\n",
    "    rho_tmp = np.ones(max_H)\n",
    "    rho_tmp[:len(rho)] = rho\n",
    "    rho_cum[i] = np.cumprod(rho_tmp)\n",
    "\n",
    "# Calculate the average cumulative importance ratio at every horizon t\n",
    "weights = rho_cum.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubly_robust_estimator(trajectory, Q, pi_0, pi_e, rho_cumulative, gamma):\n",
    "    V_DR = 0\n",
    "    T = len(trajectory)\n",
    "    for t in range(T):\n",
    "        transition = trajectory[t]\n",
    "        s = transition['s']\n",
    "        a = transition['a']\n",
    "        r = transition['r']\n",
    "        \n",
    "        Q_hat = Q[s,a]\n",
    "        V_hat = np.nansum(Q[s] * pi_e[s])\n",
    "        assert not np.isclose(pi_0[s,a], 0.0)\n",
    "        rho_1t = rho_cumulative[t]\n",
    "        if t == 0:\n",
    "            rho_1t_1 = 1.0\n",
    "        else:\n",
    "            rho_1t_1 = rho_cumulative[t-1]\n",
    "        \n",
    "        V_DR = V_DR + np.power(gamma, t) * (rho_1t * r - (rho_1t * Q_hat - rho_1t_1 * V_hat))\n",
    "    \n",
    "    return V_DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_doubly_robust_estimator(trajectory, Q, pi_0, pi_e, rho_cumulative, weight_t, gamma):\n",
    "    V_WDR = 0\n",
    "    T = len(trajectory)\n",
    "    for t in range(T):\n",
    "        transition = trajectory[t]\n",
    "        s = transition['s']\n",
    "        a = transition['a']\n",
    "        r = transition['r']\n",
    "        \n",
    "        Q_hat = Q[s,a]\n",
    "        V_hat = np.nansum(Q[s] * pi_e[s])\n",
    "        assert not np.isclose(pi_0[s,a], 0.0)\n",
    "        rho_1t = rho_cumulative[t] / weight_t[t]\n",
    "        if t == 0:\n",
    "            rho_1t_1 = 1.0\n",
    "        else:\n",
    "            rho_1t_1 = rho_cumulative[t-1] / weight_t[t-1]\n",
    "        \n",
    "        V_WDR = V_WDR + np.power(gamma, t) * (rho_1t * r - (rho_1t * Q_hat - rho_1t_1 * V_hat))\n",
    "    \n",
    "    return V_WDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_DR = [\n",
    "    doubly_robust_estimator(traj, Q_star, pi_0, pi_e, rho_cumulative, gamma) \n",
    "    for traj, rho_cumulative in zip(trajectories, rho_cum)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.58035245184213"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.clip(V_DR, -100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 627.22it/s]\n"
     ]
    }
   ],
   "source": [
    "V_DR_b = []\n",
    "for i in tqdm(range(1000)):\n",
    "    V_DR_boot = utils.resample(V_DR, replace=True, random_state=i)\n",
    "    V_DR_b.append(np.mean(np.clip(V_DR_boot, -100, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91.56139534310027, 0.30995180180626747)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(V_DR_b), np.std(V_DR_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_WDR = [\n",
    "    weighted_doubly_robust_estimator(traj, Q_star, pi_0, pi_e, rho_cumulative, weights, gamma) \n",
    "    for traj, rho_cumulative in zip(trajectories, rho_cum)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.21003694963349"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.clip(V_WDR, -100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 755.87it/s]\n"
     ]
    }
   ],
   "source": [
    "V_WDR_b = []\n",
    "for i in tqdm(range(1000)):\n",
    "    V_WDR_boot = utils.resample(V_WDR, replace=True, random_state=i)\n",
    "    V_WDR_b.append(np.mean(np.clip(V_WDR_boot, -100, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92.20258930477415, 0.22843724565578843)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(V_WDR_b), np.std(V_WDR_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def doubly_robust_estimator_recursive(trajectory, Q, pi_0, pi_e, gamma, t=0):\n",
    "    T = len(trajectory)\n",
    "    \n",
    "    if t == T:\n",
    "        V_DR = 0\n",
    "        return V_DR\n",
    "    \n",
    "    transition = trajectory[t]\n",
    "    s = transition['s']\n",
    "    a = transition['a']\n",
    "    r = transition['r']\n",
    "    \n",
    "    Q_hat = Q[s,a]\n",
    "    V_hat = np.nansum(Q_star[s] * pi_e[s])\n",
    "    assert not np.isclose(pi_0[s,a], 0.0)\n",
    "    rho = pi_e[s,a] / pi_0[s,a]\n",
    "    \n",
    "    V_DR = doubly_robust_estimator_recursive(trajectory, Q, pi_0, pi_e, gamma, t+1)\n",
    "    \n",
    "    return V_hat + rho * (r + gamma * V_DR - Q_hat)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "V_DRr = [\n",
    "    doubly_robust_estimator_recursive(traj, Q_star, pi_0, pi_e, gamma) \n",
    "    for traj in trajectories\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.mean(np.clip(V_DRr, -100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trajectory = [\n",
    "    {'s': 0, 'a': 0, 'r': 1},\n",
    "    {'s': 1, 'a': 1, 'r': 1},\n",
    "    {'s': 2, 'a': 0, 'r': 0},\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pi_0 = np.array([[.5,.5], [.5,.5], [.5,.5]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q = np.array([[2,1], [0,1], [0,0.]])\n",
    "pi_e = np.array([[1,0], [0,1], [.5,.5]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rho = []\n",
    "for transition in trajectory:\n",
    "    s = transition['s']\n",
    "    a = transition['a']\n",
    "    rho_t = pi_e[s,a] / pi_0[s, a]\n",
    "    rho.append(rho_t)\n",
    "rho_all.append(np.array(rho))\n",
    "rho_cumulative = np.cumprod(rho_tmp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "doubly_robust_estimator(trajectory, Q, rho_cumulative, gamma=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q = np.array([[1.5,0.5], [0,1], [0,0.]])\n",
    "pi_e = np.array([[0.5,0.5], [0.5,.5], [.5,.5]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rho = []\n",
    "for transition in trajectory:\n",
    "    s = transition['s']\n",
    "    a = transition['a']\n",
    "    rho_t = pi_e[s,a] / pi_0[s, a]\n",
    "    rho.append(rho_t)\n",
    "rho_all.append(np.array(rho))\n",
    "rho_cumulative = np.cumprod(rho_tmp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "doubly_robust_estimator(trajectory, Q, rho_cumulative, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
